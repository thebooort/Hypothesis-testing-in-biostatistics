\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{pgf,tikz}
\usepackage{graphicx}
\usepackage{float}
\usepackage{cite}
\usepackage{enumerate}
\usepackage{courier}
\usepackage{listings}
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize\ttfamily,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}
\usepackage{hyperref}
%\graphicspath{ {-} }
\usepackage[toc,page]{appendix}
\newtheorem{theorem}{Teorema}
%opening
\title{Hypothesis testing in biostatistics}
\author{Ruhugu, cocoseva, thebooort}

\begin{document}

\maketitle

\begin{abstract}
We do science á.Just for books to appear in our bibliography for now:
\cite{velez1993principios} \cite{rosner2015fundamentals}
\end{abstract}

\section{Summary and utilities del \cite{velez1993principios} }
\subsection{Tema 7}
\subsubsection{metodo de los momentos:}
Igualar los primeros momentos teóricos poblacionales (aquellos no constantes) a los correspondientes momentos muestrales hasta obtener un sistema de ecuaciones resoluble:
$$E_\theta[X^r]=\alpha(\theta_1,...)$$
$$a_r=\frac{1}{n}\sum_{i=1}^{n}X_i^r$$
$$\alpha_r=a_r $$
Aunque pueden funcionar carecen de justificación seria.
\subsubsection{metodo maxima verosimilitud}
Dada una m.a.s. de un apoblacion, la aproximacion de los parametros debe hacerse como aquella que maximiza la probabilidad de obtener esa m.a.s.
Special guest: ecuaciones de verosimilitud:
$$\frac{\partial}{\partial\theta_j}log f_\theta(x_1,x_2,...)=0$$
$$\forall j$$
\subsubsection{propiedades asintoticas de los estimadores de maxima vero1similitud}
Quien dice esto dice cascar dos teoremas. No creo que sean main point del trabajo, pero se pueden mirar
\subsubsection{estimacion bayesiana}
Esto si que creo que no entra nada, pasando.
\subsubsection{estimacion minimo cuadratica}
Dados los vectores de prediccion y experimentacion, ajustarlos de manera que la norma eculidea entre ellos sea la minima. 
\subsubsection{Ejercicios con aspectos teoricos pero no hay ej. signi de lo que buscamos}
\subsection{Tema 8}
\subsubsection{Intro}
Hipotesis que especifican totalmente la distribucion poblacional : hipotesis simples (constituidas por una unica funcion de distribucion)

Hipótesis  que comprenden varias distribuciones poblacionales se califican de: hipótesis compuestas.

So much tralla con el lema de Neyman-Pearson.

Tema 8 y 9 : paramétricos
Tema 10 no paramétrico (buscamos contrastar propiedad global de la distribución)
\subsubsection{Planteamiento general de los contrastes de hipótesis}
Sea $H_0$ la hipotesis nula y $H_1$ la hipotesis alternativa. El problema del contraste de hipotesis consiste en aceptar o rechazar $H_0$.

Tendremos que dividir para ello el espacio muestral  en dos regiones distintas: region critica (rechazo) region de aceptacion (aceptacion).
Esto nos lleva a los test no aleatorizados.

Si queremos tener un test aleatorizado: un test a. es cualquier funcion ($\phi$) mediable que vaya del espacio de muestras a $[0,1]$ (funcion critica del test), de manera que esa expresa la probabilidad de rechazar la hipotesis nula cuando se observa la muestra.
tendremos, pues probabilidad $\phi$ de rechazar $H_0$ y $1-\phi$ de no hacerlo. 

Tipos de errores: tipo I : rechazar $H_0$ cuando es cierta . tipo II: aceptar $H_0$ cuando es falsa.

Por tanto a la hora de plantear o diseñar un test de hipotesis:
1.fijar una cota para cometer error de tipo 1 , $\alpha$(nivel de significacion)

2. Excluir todos los test que no impongan que la probabilidad de rechazar $H_0$ cuando es cierta no supere el valor de $\alpha$  

3. Entre los test no excluidos por la condicion anterior, tratar de minimizar la probabilidad de error de tipo II.


En el marco de los problemas parametricos, el criterio descrito para la seleccion de test puede formularse como:


Si la distribucion teorica depende de un parametro $\theta \in \Theta$ acerca del cual hay que contrastar la hipotesis nula $H_0: \theta \in \Theta_0$ frente a la alternativa $H_1: \theta \in \Theta_1$ se denomina funcion de potencia, $\beta(\theta)$, de un test a la probabilidad de rechazar $H_0$ cuando el valor del parametro es $\theta$. Es decir, si se trata de un test no aleatorizado de region critica C entonces: $$\beta(\theta)=P_\theta(C)$$
mientras que en general, para un test de funcion critica $\varphi$, es $$\beta(\theta)=E_\theta[\varphi(X_1,...,X_n)].$$
Un test tiene nivel de significacion $\alpha$ si es:  $$\beta(\theta)\leq\alpha \text{ para cada } \theta \in \Theta_0;$$
y se denomina tamaño del test al número: $$sup_{\theta\in\Theta_0}\beta(\theta).$$

Es deseable que tamaño y nivel de significacion coincidan, verificandose: 
$$sup_{\theta\in\Theta_0}\beta(\theta)=\alpha$$

Para distribuciones discretas tendremos que recurrir a test aleatorizados en los cuales variar $\varphi$ de forma continua.

Si tenemos que hacer varios test de funciones criticas podemos obtener una ordenacion parcial de los test mediante la función potencia.

Lo que se suele hacer es diseñar un test de manera que obtengamos la funcion potencia dependiente de $\alpha$ y que se decidad con todas las curvas de potencia cual nos viene bien. Sin embargo esto a menudo es dificil. Por tanto lo que se hace es proceder al diseño en funcion de $\alpha$ y una vez obtenida la muestra concreta, observar el nivel de significacion mas pequeño para el que tal muestra obliga a rechazar la hipotesis nula, éste numero es el p-valor o nivel critico (indica el apoyo que la hipotesis nula recibe de las observaciones, cuanto más grande, mas confirmada queda la hipotesis nula.)


Un nivel critico superior a 0,1 es apoyo suficiente para mantenerr la hipotesis nula. Cuanto mas cercana a cero se encuentre mas confiadamente podemos rechazar la hipotesis nula ( no perder de vista la probabilidad de error tipo II)

\subsubsection{Contraste de hipótesis simple frente a simple}
metodo sistematico para determinar los test de maxima potencia en cualquier contraste de hipotesis simple frente a simple:
Test no aleatorizado:
Lema de Neyman-Pearson y posterior ejemplo.
\begin{theorem}
Dada una muestra aleatoria con distribucion $P_\theta$ sea $f_\theta(x_1,...,x_n)$ su funcion de densidad o de probabilidad (segun que la poblacion sea continua o discreta). Si $C^*\subset X$ es tal que: $$\{(x_1,...,x_n)\in X | f_\theta \ge kf_\theta\}\subset C^*\subset\{(x_1,...,x_n)\in X | f_\theta \geq kf_\theta\}$$
para alguna constante $k>0$ y es $P_theta_0(C*)=\alpha$, entonces $C^*$ es la region critica de un test de nivel de significacion $\alpha$ para contrastar $H_0:\theta =\theta_0$ frente a $H_1: \theta=\theta_1$, de máxima potencia dentro de la familia de test no aleatorizados.
\end{theorem}

 También se destacan casos discretos. Los vamos a hacer?
 
 \subsubsection{Contrastes de hipótesis unilaterales}


Es habitual que la hipotesis alternativa no esté tan bien definida. Lo que habitualmente se tiene en la practica son situaciones de la forma $H_0: \theta \geq \Theta$ frente a $H_1: \theta < \Theta$ o viceversa, que reciben el nombre de test unilaterales. Vemos como podemos obtener test uniformemmente de maxima potencia para contrastar hipotesis unilaterales:
\begin{theorem}
	Karlin-Rubin: Si la distribucion $P_\theta$ de la muestra tiene razon de verosimilitud monotona el estadistico $T(x_1,..,x_n)$ entonces:
	\begin{enumerate}[a]
		\item Para cada $\alpha\in(0,1)$ existe un test $\varphi$ de tamaño $\alpha$ y uniformemente de maxima potencia para contrastar $H_0: \theta \leq\theta_0$ frente a $H_1: \theta >\theta_0$ que es de la forma: 
		
		\item todo test con funcion critica de la forma anterior tiene funcion de potencia $\beta()\theta$ estrictamente creciente, mientras sea $0<\beta(\theta)<1.$
		\item Para cualquier test $\varphi'$ con $E_{\theta_0}[\varphi']=\alpha$ se cumple $E_{\theta_0}[\varphi]\leq E_{\theta_0}[\varphi']$ para cualquier $\theta \leq \theta_0$.
	\end{enumerate}
\end{theorem}
Le siguen la demostracion y un ejemplo.

\subsubsection{Hipotesis bilaterales}
Son hipotesis de la forma parametro=$\theta_0$ frente a parametro $\neq\theta_0$.
AQUI YA SALE LA NORMAL!!! :D
Introduccion del concepto de test insesgado: La probabillidad de rechazar $H_0$ cuando es falsa es mauor que la de rechazarla cuando es cierta (notese que cualquier  test uniformemente de maxima potencia es insesgado).


Introduce el teorema de Lehmann pero creo que nos lo podemos saltar.

\subsection{Tema 9: Metodos de contraste.}

\subsubsection{Test de tazon de verosimilitudes}
El test se utiliza en situaciones en las que se desea contrastar si un parametro de la distribucion de la muestra pertenece a un subconjunto del espacio de parametros frente al complementario de ese conjunto.

El test se basa em que para una muestra fija, su verosimilitud $f_\theta(x_1,...,x_n)$ es una medida de lo bien que explica el valor $\theta$ del parametro los resultados obtenidos. Por consiguiente $ sup_{\theta_0\in\Theta_0}f_\theta(x_1,...,x_n) $ supone un indice acerca de la mejor explicacion de la muestra que puede obtenerse baho $ H_0 $ y coincide con la cantidad que se puede calcular usando el estimador de maxima verosimilitud $ f_{\hat{\theta}}(x_1,...,x_n) $. $sup_{\theta\in\Theta}f_\theta(x_1,...,x_n) $ proporciona tal indice entre todos los posibles valores del parametro y pasa lo mismo con el estimador de maxima verosimilitud.

Si $ f_{\theta_0} $ es mas bajo que la otra implica que la explicacion de los resultados sobre la base de que $H_0$ es cierta es mucho peor que la explicacion si tal restriccion; por tanto rechazamo $H_0$
La comparacion entre ambas se hace con el cociente

Se emplearan test no aleatorizados cuando la distribucion del estadistico cociente sea continua. La distribucion que se coge es la $\chi^2$.

El resto son ejemplos, tendríamos que ir eligiendolos.

\subsubsection{Constrastes multiples}

\subsection{Tema 10: Contrastes globales sobre la distribución poblacional (tests no paramétricos)}
\subsubsection{Introducción}
En muchas ocasiones es necesario emitir un juicio estadístico sobre la dist. poblecional en su conjunto: ejemplo
\begin{itemize}
\item M.a. de una población, ¿puede admitirse que la dist. poblacional coincide con una dada? Problema de la bondad del ajuste
\item Teniendo varias m.a.s., puede admitirse que provengan de la misma distribución teórica? Problema de homogeneidad
\item Se observan dos o más características de los elementos de una población, son independientes? Problema de la independencia.
\end{itemize}

Se distinguen dos tipos de planteamientos, a saber:
\begin{enumerate}
\item Descomponer el recorrido de la distribución teórica en un número finito de subconjuntosy clasificar las observaciones muestrales según el conjunto al que pertenezcan. Después, comparar las frecuencias observadas de cada subconjunto con las que corresponderían a la distribución teórica. Esto da lugar a los tests $\chi^2$, los cuales reducen un problema no paramétrico a uno que sí lo es.
\item Unas la distribución muestral $F^*_n(x)$ para compararla con la distribución teórica o para compararlas entre sí. Midiendo la distancia entre ambas puede saberse si es o no significativa siempre que se tenga un patrón
\end{enumerate}

\subsubsection{Contrastes $\chi^2$ de bondad del ajuste}
\textbf{Hipótesis simple} \\
Se dispone de una m.a.s. de tamaño n de una población con distribución desconocida $F$. Contrastar si puede aceptarse la hipótesis $H_0 : F = F_0$ donde $F_0$ es una distribución especificada (no parsamétrica). La hipótesis nula $H_1$ se trata entonces de todas las distribuciones distintas a $F_0$.

El recorrido de la distribución poblacional se divide en $k$ conjuntos disjuntos $A_1,...,A_k$. Sea $p^0_i$ la probabilidad de cada $A_i$ bajo $F_0$ y $p_i$ la probabilidad desconocida que la distribución teórica asigna a cada $A_i$:

La variable aleatoria que cuenta el nº de observaciones de la muestra en cada subconjunto tiene distribución multinomial con parámetros $n$ y $\textbf{p}= (p_1,...,p_k)$:
$$P\{N_1=n_1,...,N_k=n_k\}= \frac{n!}{n_1!\cdots n_k!} p^{n_1}_1\cdots p^{n_k}_k$$

Se ha logrado pues pasar a un test paramétrico de $H_0: $\textbf{$p$} =\textbf{$p^0$} frente a la hipótesis de que el parámetro sea otro.

Por tanto, esto se puede resolver por un test de razón de verosimilitudes, aunque la tradición clásica hace que el estadístico a usar normalmente sea otro (que da los mismos resultados)(esto se puede desarrollar como mucho, no sé cuánto nos vamos a meter)

\textbf{Hipótesis compuesta} \\
La situación habitual es que la hipótesis a contrastar sea compuesta; más concretamente se especifica una familia de distribuciones con forma funcional dad pero dependiente de algunos parámetros no especificados.

Se podría pensar en hacer los dos tests por separado, i.e., realizar la estimación puntual de los parámetros para contrastar después el ajuste a la distribución poblacional que indiquen los propios datos como la más adecuada, pero para ello se necesitarían dos m.a.s. independientes (explicación de esto p.439).

Alternativa: Contrastar una hipótesis nula de la forma $F \in \{F_\theta| \theta \in \Theta \subset R^q\}$
Se procede de igual manera que con la hipótesis simple, terminando por comparar paramétricamente una distribución multinomial (de nuevo, esto se puede extender lo que queramos, según cómo vaya lo demás).

\subsubsection{Contraste $\chi^2$ de homogeneidad}
¿Tenemos $m$ muestras de tamaños $n_1, n_2,...,n_m$ o bien una única muestra de tamaño $n_1+n_2+\cdots + n_m$?

Al ser un test $\chi ^2$ el procedimiento es el mismo: dividir en subconjuntos, clasificar las observaciones muestrales y convertirlo todo en un test paramétrico sobre los parámetros de la distribución multinomial que sigue la variable aleatoria que cuenta el número de observaciones de la muestra en cada subconjunto. (Again, se alarga tanto como queráis).

\subsubsection{Contraste $\chi^2$ de independencia}
Se tienen $n$ elementos de una población en los que se observan 2 caracterísiticas, $X$ e $Y$ obteniéndose una m.a.s. bidimensional $(X_1,Y_1),...,(X_n,Y_n)$, ¿son estas características independientes?
SE PROCEDE DE LA MISMA MANERA POR SER UN TEST CHI CUADRADO

\subsubsection{Contraste de Kolmogorov-Smirnov }
Desventajas de los tests $\chi^2$ : al discretizar las observaciones muestrales en conjuntos de una cierta partición , en el caso de las distribuciones continuas se ignora el valor exacto de las observaciones, lo que puede dar lugar a errores significativos en caso de que la muestra no sea lo suficientemente grande.

Por tanto, para el caso de bondad del ajuste a una distribución unidimensional de tipo continuo es preferible el uso de un pocedimiento alternativo: en lugar de estudiar la diferencia entre los histogramas de frecuencias se compoara la función de distribución muestral con la función de distribución teórica.

La función de distribución muestral asociada a  una m.a. $x_1, x_2,..,x_n$ es 
$$F^*_n(x) = \frac{nº de x_i \leq x}{n} = \left\{ \begin{array}{lcc}
             0 &   si  & x \leq x_{(1)} \\
             \\ i/n &  si & x_{(i)} < x < x_{(i+1)} \\
             \\ 1 &  si  & x \geq x_{(n)}
             \end{array}
   \right. $$
donde $x_{(1)},...,x_{(n)}$ son los elementos de la m.a. ordenada.

Si estamos frente a una m.a.s. de una población descrita por la variable aleatoria $X$ con función de distribución $F$, por el \textbf{Teorema de Glivenko-Cantelli} se tiene que hay probabilidad 1 de obtener una sucesión muestral con la cual $F^*_n(x)$ converja a $F(x)$ uniformemente en $x$,i.e.,
$$\sup |F^*_n(x) - F(x)| \longrightarrow^{c.s.} 0$$
% esto se tiene que poder escribir mejor

Teniendo en cuenta que $F$ es desconocida y que se pretende contrastar la hipótesis nula $H_0 : F_0 = F$ usaremos como estadístico
$$\Delta_n = \sup |F^*_n(x) - F(x)|  $$
y por tanto tendremos como región crítica $\{\Delta_n > k\}$. Aunque esto de poco sirve si no se conoce la distribución de $\Delta_n$ bajo la hipótesis nula para determinar el nivel crítico $k$ a partir del cual sus valores son significativos de la existencia de una desviación de $F$ respecto a $F_0$.

\begin{theorem}
(Lema) Si $F = F_0$ y $F_0$ es continua, la distribución de $\Delta_n$ no depende de $F_0$
\end{theorem}
Con la demostración se da una expresión integral de la distribución buscada (p.456) que no proporciona un resultado explícito pero que permite tabular la distribución de $\Delta_n$ para valores pequeños de $n$.

Para valores grandes de $n$ se puede usar la distribución $K$ de Kolmogorov:
$$P\{\sqrt{n}\Delta_n \leq z \} \longrightarrow \sum^{\infty}_{K=-\infty} (-1)^{k} e^{-2k^2 z^2}  $$

que fue tabulada por Smirnov.

Puesto que los resultados sobre la distribución de $\Delta_n$ provienen de suponer que la distribución poblacional es continua, es obvio que sólo se podrá utilizar este test en este tipo de distribuciones.

Como pega, comentar que para hipótesis compuestas es necesario tener dos muestras independientes, cosa que no pasaba con los tests $\chi^2$.



\subsection{Contraste de homogeneidad de Kolmogorov-Smirnov}

Se dispone de dos m.a.s. independientes, $X_1,...,X_n $ e $Y_1,...,Y_m$ y se quiere contrastar la hipótesis nula $H_0:F_X = F_Y$.

Si dichas distribuciones son de tipo continuo, los tests $\chi^2$ tienen los mismos problemas que en la sección anterior y sólo podrían usarse para muestras grandes.

Para muestras pequeñas, se usará la misma técnica de los estadísticos de Kolmogorov-Smirnov. Considerando
\begin{center}
$F^*_n (x)=\frac{1}{n}\sum_{i=1}^n I_{\{X_i \leq x\}}$ y $G^*_n (x)=\frac{1}{m}\sum_{i=1}^m I_{\{Y_i \leq x\}}$
\end{center}
construimos el estadístico de Kolmogorov-Smirnov correspondiente a ambas muestras $$\Delta_{n,m}=\sup|F^*_n(x)-G^*_m (x)|$$
Contrastamos la hipótesis $H_0$ con un test de región crítica $\{ \Delta_{n,m} > k\}$.

La distribución del estadístico $\Delta_{n,m}$ se pueden determinar por métodos combinatorios, aunque también están tabulados para $n$ y $m$ pequeños.

Para $n$ y $m$ grandes, se puede usar los resultados de la distribución asintótica de Kolmogorov:
$$P\{ \sqrt{\frac{nm}{n+m}}\Delta_{n,m}\leq z\}\longrightarrow \sum^{\infty}_{i=-\infty}(-1)^i e^{-2i^2z^2}$$


\subsection{Contrastes de Independencia}
Para contrastar la independencia entre dos características poblacionales continuas $X$ e $Y$, hay otras opciones como el test $\tau$ de Kendall, el test de rachas o el test de coeficiente de correlación entre rangos de Spearman.

ATENCIÓN : ¿esto queréis desarrolarlo? Lo digo porque es una puta mierda\\
También me he saltado los tests de posición*, echadle un ojo y decidme qué hago, que igual se nos está haciendo esto muy grande o algo no? Yo hago lo que me digáis

* porque son una mierda, porque son una mierda de escribir y porque son una mierda, pero ojo, que yo los escribo si os gustan. No sé cómo de exhaustivo queréis hacer esto.



































\bibliographystyle{alpha}
\bibliography{bibliography/bibliografia}

\end{document}
