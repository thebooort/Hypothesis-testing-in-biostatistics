\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{pgf,tikz}
\usepackage{graphicx}
\usepackage{float}
\usepackage{cite}
\usepackage{enumerate}
\usepackage{courier}
\usepackage{listings}
\usepackage{color}
\usepackage{todonotes}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize\ttfamily,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}
\usepackage{hyperref}
%\graphicspath{ {-} }
\usepackage[toc,page]{appendix}
\newtheorem{theorem}{Teorema}
%opening
\title{Hypothesis testing in biostatistics}

\author{Rubén Hurtado, Bartolomé Ortiz , Cristina Seva }

\begin{document}

\maketitle

\begin{abstract}
El presente expone un recorrido por los principales conceptos y fundamentos del contraste de hipótesis. En él proporcionamos un enfoque estadístico de este área centrado en test paramétricos (para una o dos poblaciones normales) y test no paramétricos (recogiendo en particular bondad de ajuste, independencia y localizacion) . 
\end{abstract}


\section{Base teórica del contraste de hipótesis}
\subsection{Introdución}
El contraste de hipótesis es un área de la inferencia estadística que se ocupa de conocer determinados aspectos de la distribución que tiene nuestro experimento.

Más concretamente, \textit{"la finalidad de un contraste de hipótesis es decidir si una determinada hipótesis, afirmación, o conjetura, sobre la distribución poblacional estudiada, es confirmada o invalidada estadísticamente a partir de las observaciones contenidas en la muestra"}, \cite{velez1993principios}.

En general, dentro de los test de hipótesis, vamos a llamar \textbf{hipótesis nula o $H_0$} a la hipótesis que se asume sobre nuestra distribución y la cual se pretende contrastar. Frente a ella, nos encontramos la \textbf{hipótesis alternativa o $H_1$}, que agrupa aquellas distribuciones que no poseen $H_0$ como cualidad.

A parte, también destacamos otra división usual:
\begin{itemize}
	\item \textbf{Hipótesis simples}: son aquéllas que especifican totalmente la distribución poblacional (constituidas por una única función de distribución)
	\item \textbf{Hipótesis compuestas}: Hipótesis  que comprenden varias distribuciones poblacionales 
\end{itemize}

\subsection{Planteamiento general de los contrastes de hipótesis}
Sea $H_0$ la hipótesis nula y $H_1$ la hipótesis alternativa. El problema del contraste de hipótesis consiste en aceptar o rechazar $H_0$.

\subsubsection{Tipos}
Habitualmente, para tomar esta decisión podemos seguir un proceso que puede ser o no aleatorio: 
\begin{itemize}
	\item si se lleva a cabo dividiendo el espacio muestral $\Omega$ en dos regiones distintas:
	\begin{itemize}
		\item región crítica (rechazo)
		\item región de aceptación 
	\end{itemize} 
	hablamos de test no aleatorio.
	\item Si queremos tener un test aleatorizado: escogeremos una función $\phi$ medible que vaya del espacio de muestra a $[0,1]$ (función crítica del test), de manera que esta función exprese la probabilidad de rechazar la hipótesis nula cuando se observa la muestra $(x_1,...,x_n)$.
	Tendremos pues, probabilidad $\phi$ de rechazar $H_0$ y $1-\phi$ de no hacerlo. 
\end{itemize}

\subsubsection{Errores}

Tipos de errores: tipo I : rechazar $H_0$ cuando es cierta ; tipo II: aceptar $H_0$ cuando es falsa.

\subsubsection{Criterios de elección}
A la hora de plantear o diseñar un test de hipótesis buscamos la disminución de todos los tipos de error; es habitual que esto sea difícil de alcanzar, puesto que disminuir la probabilidad de cometer un erro de tipo I influye positivamente en la probabilidad de cometer error de tipo II. Ante esta amplitud de posibilidades, existe un criterio tradicional para para diseñar los test:
\begin{enumerate}
	\item Fijar una cota para cometer error de tipo 1 , $\alpha$, llamada nivel de significación.
	\item Excluir todos los test que no impongan que la probabilidad de rechazar $H_0$ cuando es cierta no supere el valor de $\alpha$ . 
	\item  Entre los test no excluidos por la condición anterior, tratar de minimizar la probabilidad de error de tipo II.
\end{enumerate}


\section{Test paramétricos: Distribución Normal}
\subsection{Introducción}
En el marco de los problemas paramétricos, el criterio descrito para la selección de test puede formularse como:

\textit{ Si la distribución teórica depende de un parámetro $\theta \in \Theta$ acerca del cual hay que contrastar la hipótesis nula $H_0: \theta \in \Theta_0$ frente a la alternativa $H_1: \theta \in \Theta_1$ se denomina funcion de potencia, $\beta(\theta)$, de un test a la probabilidad de rechazar $H_0$ cuando el valor del parametro es $\theta$. Es decir, si se trata de un test no aleatorizado de región crítica C entonces: $$\beta(\theta)=P_\theta(C)$$
mientras que en general, para un test de función crítica $\varphi$, es $$\beta(\theta)=E_\theta[\varphi(X_1,...,X_n)].$$
Un test tiene nivel de significación $\alpha$ si es:  $$\beta(\theta)\leq\alpha \text{ para cada } \theta \in \Theta_0;$$
y se denomina tamaño del test al número: $$sup_{\theta\in\Theta_0}\beta(\theta).$$
Es deseable que tamaño y nivel de significación coincidan, verificándose: 
$$sup_{\theta\in\Theta_0}\beta(\theta)=\alpha$$ }

Una vez tenemos los conceptos básicos en cuanto al constraste de hipótesis, vamos a ofrecer un pequeño recorrido por los test paramétricos que están relacionados con las distribuciones normales.


 \subsection{Contraste T de Student}
 El test t de Student o Test-T es cualquier prueba en la que el estadístico utilizado tiene una distribución t de Student si la hipótesis nula es cierta.
 
 Este test se suele utilizar cuando la población estudiada sigue una distribución normal pero el tamaño muestral es demasiado pequeño como para que el estadístico en el que está basada la inferencia esté normalmente distribuido, utilizándose una estimación de la desviación típica en lugar del valor real. 
 
 En la bioestadística podemos tener casos en los cuales nuestro tamaño de muestra sera pequeño. Esto por ejemplo puede darse en medicina cuando tratamos a grupo reducido de pacientes. 
 \subsubsection{Contraste t de una muestra para la media de una distribución normal con varianza desconocida (Media alternativa <media nula)}
 En este caso enfrentamos la hipótesis de que nuestros datos tengan una determinada media, frente a la posibilidad  de que la media sea menor: 
 \begin{itemize}
 	\item $H_0:\mu=\mu_0$
 	\item $H_1: \mu<mu_0$
 \end{itemize}
 Con la particularidad de que la varianza nos es desconocida.
 
 En este caso el estadístico para nuestro test es: 
 $$t=\frac{\bar{x}-\mu_0}{s/\sqrt{n}}$$
 Un vez, obtenido, elejimos un nivel de significación $\alpha$ y finalmente:
 \begin{itemize}
 	\item Si $t<t_{n-1,\alpha}$, rechazamos $H_0$
 	\item Si $t<t_{n-1,\alpha}$, aceptamos $H_0$
 \end{itemize}
 Para lo cual deberemos usar una tabla de la distribución T de Student o un ordenador.
 Añadimos también que el p-valor podría calcularse vía:
 $$p_{valor}=P[t_{n-1}\leq t]$$
 
 \subsubsection{Contraste t de una muestra para la media de una distribución normal con varianza desconocida (Media alternativa >media nula)}
 En este caso enfrentamos la hipótesis que completa el estado anterior, es decir, queremos saber si nuestros datos tienen una determinada media, frente a la posibilidad  de que la media sea mayor: 
 \begin{itemize}
 	\item $H_0:\mu=\mu_0$
 	\item $H_1: \mu>mu_0$
 \end{itemize}
 Con la particularidad de que la varianza nos es desconocida.
 
 En este caso el estadístico para nuestro test es el mismo: 
 $$t=\frac{\bar{x}-\mu_0}{s/\sqrt{n}}$$
 Un vez, obtenido, elegimos un nivel de significación $\alpha$ y finalmente:
 \begin{itemize}
 	\item Si $t>t_{n-1,1-\alpha}$, rechazamos $H_0$
 	\item Si $t\leq t_{n-1,1-\alpha}$, aceptamoss $H_0$
 \end{itemize}
 Para lo cual deberemos usar una tabla de la distribución T de Student o un ordenador.
 Añadimos también que el p-valor podría calcularse vía:
 $$p_{valor}=P[t_{n-1}> t]$$
 
 \subsubsection*{Caso practico en bioestadística}
 (De \cite{rosner2015fundamentals}) 
Supongamos que estamos examinando el nivel de colesterol de n=10 niños cuyos padres murieron de una enfermedad cardiaca. Mediante las pruebas encontramos que la media de nuestra muestra es de 200 mg/dL con una disviación típica de 50mg/dL. Suponemos que es un parametro que se distribuye como una normal, pero nuestro grupo es demasiado pequeño, por lo que usamos un test T de Student para comparar si la media de colesterol es significativamente mayor aquí que en la poblacion general, la cual posee 175 mg/dL de media.
Planteamos por tanto el problema:
\begin{itemize}
	\item $H_0:\mu=175$
	\item $H_1: \mu>mu_0$
\end{itemize}
Con nivel de significación $\alpha=0.05$
$$t=\frac{200-175}{50/\sqrt{10}}=\frac{25}{15.81}=1.58$$
ahora comprobamos:
$$t<t_{n-1,1-\alpha}=t_{9,0.95}=1.8333$$
Por lo que acpetamos la hipótesis nula.

\subsubsection{Contraste t de una muestra para la media de una distribución normal con varianza desconocida. Alternativa bilateral}
Es habitual no poder encajar los test de hipótesis en test unilaterales sobre la distribución. Por ello, añadimos un test bilateral para discernir en problemas en los que se busca comprobar la igualdad o desigualdad de un parámetro.

En este caso enfrentamos la hipótesis de que nuestros datos tengan una determinada media, frente a la posibilidad  de que la media sea menor: 
\begin{itemize}
	\item $H_0:\mu=\mu_0$
	\item $H_1: \mu\neq mu_0$
\end{itemize}
Con la particularidad de que la varianza nos es desconocida.

En este caso el estadístico vuelve a ser: 
$$t=\frac{\bar{x}-\mu_0}{s/\sqrt{n}}$$
Un vez, obtenido, elejimos un nivel de significación $\alpha$ y finalmente:
\begin{itemize}
	\item Si $|t|>t_{n-1,1-\alpha/2}$, rechazamos $H_0$
	\item Si $|t|\leq t_{n-1,1-\alpha/2}$, aceptamos $H_0$
\end{itemize}
Para lo cual deberemos usar una tabla de la distribución T de Student o un ordenador.
La obtencion del p-valor para este caso es más complicada:
$$p_{valor} = \begin{cases} 2P[t_{n-1}\leq t], & \mbox{si } t\leq 0 \\ 2(1-P[t_{n-1}\leq t]), & \mbox{si } t>0 \end{cases}$$

\subsection{Contraste (bilateral) $\chi^2$ para la varianza de una distribución normal}

Terminamos la seccion de test para una sola poblacion aportando un caso en el que nos interesa la varianza de la poblacion que suponemos normal.

En este caso enfrentamos la hipótesis de que nuestros datos tengan una determinada varianza, frente a la posibilidad  de que la varianza no sea la esperada: 
\begin{itemize}
	\item $H_0:\sigma^2=\sigma^2_0$
	\item $H_1: \sigma^2\neq\sigma^2_0$
\end{itemize}

En este caso el estadístico vuelve a ser: 
$$X^2=\frac{(n-1)S^2}{\sigma^2}$$
Un vez, obtenido, elejimos un nivel de significación $\alpha$ y finalmente, tras observar que el estadístico viene aproximado por una distribución $\chi^2$:
\begin{itemize}
	\item Si $X^2<\chi^2_{n-1,\alpha/2}$ o,$X^2>\chi^2_{n-1,1-\alpha/2}$, rechazamos $H_0$
	\item Si $\chi^2_{n-1,\alpha/2}\leq X^2\leq\chi^2_{n-1,1-\alpha/2}$, aceptamos $H_0$
\end{itemize}
Para lo cual deberemos usar una tabla de la distribución $\chi^2$ o un ordenador.

 \subsubsection*{Caso practico en bioestadística}
(De \cite{rosner2015fundamentals}) Trasladar el que empieza en el ejemplo 6.39 y sigue por 7.46 y 7.47


\subsection{Contrastes para dos poblaciones normales}

\section{Contrastes globales sobre la distribución poblacional (test no paramétricos)}
\subsection{Introducción}
En muchas ocasiones es necesario emitir un juicio estadístico sobre la distribución poblacional en su conjunto, por ejemplo:
\begin{itemize}
\item Ante una muestra aleatoria de una población, ¿puede admitirse que la distribución poblacional coincide con una dada? Problema de la bondad del ajuste
\item Teniendo varias m.a.s., puede admitirse que provengan de la misma distribución teórica? Problema de homogeneidad
\item Se observan dos o más características de los elementos de una población, son independientes? Problema de la independencia.
\end{itemize}

Se distinguen dos tipos de planteamientos, a saber:
\begin{enumerate}
\item Descomponer el recorrido de la distribución teórica en un número finito de subconjuntos y clasificar las observaciones muestrales según el conjunto al que pertenezcan. Después, comparar las frecuencias observadas de cada subconjunto con las que corresponderían a la distribución teórica. Esto da lugar a los test $\chi^2$, los cuales reducen un problema no paramétrico a uno que sí lo es.
\item Unas la distribución muestral $F^*_n(x)$ para compararla con la distribución teórica o para compararlas entre sí. Midiendo la distancia entre ambas puede saberse si es o no significativa siempre que se tenga un patrón
\end{enumerate}

\subsection{Contrastes $\chi^2$ de bondad del ajuste}
\textbf{Hipótesis simple} \\
Se dispone de una m.a.s. de tamaño n de una población con distribución desconocida $F$. Se quiere contrastar si puede aceptarse la hipótesis $H_0 : F = F_0$ donde $F_0$ es una distribución especificada (no paramétrica). La hipótesis alternativa $H_1$ se trata entonces de todas las distribuciones distintas a $F_0$.

El recorrido de la distribución poblacional se divide en $k$ conjuntos disjuntos $A_1,...,A_k$. Sea $p^0_i$ la probabilidad de cada $A_i$ bajo $F_0$ y $p_i$ la probabilidad desconocida que la distribución teórica asigna a cada $A_i$:

La variable aleatoria que cuenta el número de observaciones de la muestra en cada subconjunto tiene distribución multinomial con parámetros $n$ y $\textbf{p}= (p_1,...,p_k)$:
$$P\{N_1=n_1,...,N_k=n_k\}= \frac{n!}{n_1!\cdots n_k!} p^{n_1}_1\cdots p^{n_k}_k$$

Se ha logrado pues pasar a un test paramétrico de $H_0 :   \textbf{p} = \textbf{p}^0$ frente a la hipótesis de que el parámetro sea otro.

Por tanto, esto se puede resolver por un test de razón de verosimilitudes, aunque la tradición clásica hace que el estadístico a usar normalmente sea otro que da los mismos resultados. Este se debe a que el test de razón de verosimilitudes es posterior a los test $\chi^2$.
\\

\textbf{Hipótesis compuesta} \\
La situación habitual es que la hipótesis a contrastar sea compuesta; más concretamente se especifica una familia de distribuciones con forma funcional dada pero dependiente de algunos parámetros no especificados.

Se podría pensar en hacer los dos test por separado, i.e., realizar la estimación puntual de los parámetros para contrastar después el ajuste a la distribución poblacional que indiquen los propios datos como la más adecuada, pero para ello se necesitarían dos m.a.s. independientes.

Alternativa: Contrastar una hipótesis nula de la forma $F \in \{F_\theta| \theta \in \Theta \subset R^q\}$
Se procede de igual manera que con la hipótesis simple, terminando por comparar paramétricamente una distribución multinomial.

\subsection{Contraste $\chi^2$ de homogeneidad}
¿Tenemos $m$ muestras de tamaños $n_1, n_2,...,n_m$ o bien una única muestra de tamaño $n_1+n_2+\cdots + n_m$?

Al ser un test $\chi ^2$ el procedimiento es el mismo: dividir en subconjuntos, clasificar las observaciones muestrales y convertirlo todo en un test paramétrico sobre los parámetros de la distribución multinomial que sigue la variable aleatoria que cuenta el número de observaciones de la muestra en cada subconjunto. 

\subsection{Contraste $\chi^2$ de independencia}
Se tienen $n$ elementos de una población en los que se observan 2 características, $X$ e $Y$ obteniéndose una m.a.s. bidimensional $(X_1,Y_1),...,(X_n,Y_n)$, ¿son estas características independientes? La forma de proceder vuelve a ser análoga a las anteriores, lo que nos demuestra la versatilidad de los test $\chi^2$.

\subsection{Contraste de Kolmogorov-Smirnov }
Desventajas de los tests $\chi^2$ : al discretizar las observaciones muestrales en conjuntos de una cierta partición , en el caso de las distribuciones continuas se ignora el valor exacto de las observaciones, lo que puede dar lugar a errores significativos en caso de que la muestra no sea lo suficientemente grande.

Por tanto, para el caso de bondad del ajuste a una distribución unidimensional de tipo continuo es preferible el uso de un procedimiento alternativo: en lugar de estudiar la diferencia entre los histogramas de frecuencias se compara la función de distribución muestral con la función de distribución teórica.

La función de distribución muestral asociada a  una muestra aleatoria $x_1, x_2,..,x_n$ es 
$$F^*_n(x) = \frac{nº de x_i \leq x}{n} = \left\{ \begin{array}{lcc}
             0 &   si  & x \leq x_{(1)} \\
             \\ i/n &  si & x_{(i)} < x < x_{(i+1)} \\
             \\ 1 &  si  & x \geq x_{(n)}
             \end{array}
   \right. $$
donde $x_{(1)},...,x_{(n)}$ son los elementos de la m.a. ordenada.

Si estamos frente a una muestra aleatoria simple de una población descrita por la variable aleatoria $X$ con función de distribución $F$, por el \textbf{Teorema de Glivenko-Cantelli} se tiene que hay probabilidad 1 de obtener una sucesión muestral con la cual $F^*_n(x)$ converja a $F(x)$ uniformemente en $x$, i.e.,
$$\sup |F^*_n(x) - F(x)| \xrightarrow{c.s.} 0$$
% esto se tiene que poder escribir mejor

Teniendo en cuenta que $F$ es desconocida y que se pretende contrastar la hipótesis nula $H_0 : F_0 = F$ usaremos como estadístico
$$\Delta_n = \sup |F^*_n(x) - F(x)|  $$
y por tanto tendremos como región crítica $\{\Delta_n > k\}$. Aunque esto de poco sirve si no se conoce la distribución de $\Delta_n$ bajo la hipótesis nula para determinar el nivel crítico $k$ a partir del cual sus valores son significativos de la existencia de una desviación de $F$ respecto a $F_0$.

\begin{theorem}
(Lema) Si $F = F_0$ y $F_0$ es continua, la distribución de $\Delta_n$ no depende de $F_0$
\end{theorem}
Con la demostración se da una expresión integral de la distribución buscada que no proporciona un resultado explícito pero que permite tabular la distribución de $\Delta_n$ para valores pequeños de $n$.

Para valores grandes de $n$ se puede usar la distribución $K$ de Kolmogorov:
$$P\{\sqrt{n}\Delta_n \leq z \} \longrightarrow \sum^{\infty}_{K=-\infty} (-1)^{k} e^{-2k^2 z^2}  $$

que fue tabulada por Smirnov.

Puesto que los resultados sobre la distribución de $\Delta_n$ provienen de suponer que la distribución poblacional es continua, es obvio que sólo se podrá utilizar este test en este tipo de distribuciones.

Como pega, comentar que para hipótesis compuestas es necesario tener dos muestras independientes, cosa que no pasaba con los test $\chi^2$.



\subsection{Contraste de homogeneidad de Kolmogorov-Smirnov}

Se dispone de dos muestras aleatorias simples independientes, $X_1,...,X_n $ e $Y_1,...,Y_m$ y se quiere contrastar la hipótesis nula $H_0:F_X = F_Y$.

Si dichas distribuciones son de tipo continuo, los tests $\chi^2$ tienen los mismos problemas que en la sección anterior y sólo podrían usarse para muestras grandes.

Para muestras pequeñas, se usará la misma técnica de los estadísticos de Kolmogorov-Smirnov. Considerando
\begin{center}
$F^*_n (x)=\frac{1}{n}\sum_{i=1}^n I_{\{X_i \leq x\}}$ y $G^*_n (x)=\frac{1}{m}\sum_{i=1}^m I_{\{Y_i \leq x\}}$
\end{center}
construimos el estadístico de Kolmogorov-Smirnov correspondiente a ambas muestras $$\Delta_{n,m}=\sup|F^*_n(x)-G^*_m (x)|$$
Contrastamos la hipótesis $H_0$ con un test de región crítica $\{ \Delta_{n,m} > k\}$.

La distribución del estadístico $\Delta_{n,m}$ se pueden determinar por métodos combinatorios, aunque también están tabulados para $n$ y $m$ pequeños.

Para $n$ y $m$ grandes, se puede usar los resultados de la distribución asintótica de Kolmogorov:
$$P\{ \sqrt{\frac{nm}{n+m}}\Delta_{n,m}\leq z\}\longrightarrow \sum^{\infty}_{i=-\infty}(-1)^i e^{-2i^2z^2}$$


\subsection{Contrastes de Independencia}
Para contrastar la independencia entre dos características poblacionales continuas $X$ e $Y$, hay otras opciones como el test $\tau$ de Kendall, el test de rachas o el test de coeficiente de correlación entre rangos de Spearman.

\subsection{Contrastes de Localización}
Dada una distribución unidimensional desconocida de una población, en ocasiones sólo interesa conocer su posición sobre la recta ya que se presupone que las condiciones en que se observa el fenómeno sólo pueden trasladarla, dejando invariante su forma.

Si puede admitirse la normalidad de las distribuciones, la manera de proceder sería aplicando test paramétricos sobre la media de una normal. Sin embargo, cuando no quepa esta posibilidad, lo habitual es el uso de la mediana muestral para contrastar hipótesis sobre las medianas poblacionales.

\subsubsection{Test de los signos}
Se trata de una prueba no paramétrica para comparar el rango medio de dos muestras relacionadas y determinar si existen diferencias entre ellas. Es una alternativa al test $t$ de Student cuando no se puede suponer la normalidad de las muestras.

Se dispone de una muestra aleatoria simple de tamaño $n$ proveniente de una distribución continua pero desconocida $F$ cuya mediana se denotará por $M$. Se quiere contrastar la hipótesis nula $H_0: M=m_0$frente a una delas alternativas, ya sea $M<m_0$, $M>m_0$ o simplemente $M\neq m_0$.

Por definición, $F(M)=1/2$ por lo que si $H_0$ se cumple, cabe esperar que en torno a la mitad de las observaciones estén por debajo de $m_0$ y la otra mitad esté por encima. Basaremos por tanto el contraste en el estadístico

\begin{center}
$T$ = número de observaciones muestrales mayores que $m_0$.
\end{center}

Notar que $T$ sigue una distribución binomial de parámetros $n$ y $1/2$, bajo la hipótesis nula.

La región crítica va a depender de cuál sea$H_1$, por ejemplo, si $H_1:M>m_0$, cuando $H_0$ no sea cierta, la muestra tenderá a presentar más valores superiores a $m_0$ de los esperados, por lo que la región crítica será de la forma:
$$\{T\geq k \},$$

con $k$ tal que $\frac{1}{2^n}\sum_{j=k}^{n} \binom{n}{j} < \alpha$ para que el contraste tenga nivel de significación $\alpha$. Esto es análogo para el caso $H_1: M< m_0$.

Sin embargo, para algo más general como es el caso de $H_1:M\neq m_0$, el test debe rechazar valores muy altos y muy bajos de $T$, de manera que la región crítica será $$\{T\leq k\}\cup \{T\geq n - k \}$$, con $k$ tal que $\frac{1}{2^n}\sum_{j=1}^{k} \binom{n}{j} + \frac{1}{2^n}\sum_{j=n-k}^{n} \binom{n}{j} \leq \alpha$.

Si el tamaño muestral es lo suficientemente grade, puede emplearse la aproximación normal a la distribución binomial.

\subsubsection{El test de Wilcoxon de los rangos signados}
En el caso de que la distribución pueda considerarse simétrica, además de continua, Wilcoxon propuso un test para la misma hipótesis que el test de los signos, es decir, $H_0:M =m_0$ que saca más provecho de los valores de las observaciones.

Llamemos $D_i=X_i - m_0$ a las diferencias entre las observaciones muestrales y el valor a contrastar para $M$. Podemos ordenar los valores absolutos $|D_i|$ y anotar el rango $r(|D_i|)$ que cada uno ocupa en la ordenación.  Entonces podemos usar como estadístico de contraste la suma de los rangos de las observaciones mayores que $m_0$:
$$T^+ = \sum_{i =1}^{n} r(|D_i|)I_{\{D_i>0\}}.$$

Si se cumple la hipótesis alternativa $H_1:M>m_0$, parece razonable esperar que haya más diferencias positivas que negativas y que las positivas tengan valores absolutos superiores a las negativas. Es decir, habrá que rechazar la hipótesis alternativa si $T^+$ tiene un valor alto, lo que nos lleva a tomar como región crítica $\{T^+ > k_1\}$. El resultado es simétrico para la hipótesis $H_1:M<m_0$.

Para la hipótesis más general $H_1: M \neq m_0$, la región crítica es $\{ T^+<k\}\cup\{T^+ >k'\}.$

Si llamamos $a_n(t)$ al número de asignaciones de signos a los rangos que hace $T^+=t$ se tiene $$P\{T^+ = t\}=\frac{a_n(t)}{2^n}$$ 





\section{Aplicación en Bioinformática:}
\large{Identificacion de Genes Responsables de Rasgos Cuantitativo \textit{(QuantitativeTrait Loci, QTLs)}}
\normalsize{}
\subsection{Contexto biológico}
Tras los ejemplos que se han podido observar a lo largo del texto sobre aplicaciones en bioestadística, en especial en el campo de la salud, queremos profundizar en algún aspecto que nos acerque al estudio bioinformático para complementar nuestro trabajo.

En este caso, la temática escogida es el uso que se le pueden dar a los test de hipótesis en la identificacion de genes responsables de rasgos cuantitativos. Aunque todo el estudio de este procedimiento se sale un poco del trabajo, queremos aportar una visión global de este problema biológico y el acercamiento estadístico hacia su solución basándonos en \cite{uned2}.

La problemática se centra en el estudio de los rasgos poligenéticos (cuantitativos), es decir, características de los seres vivos que surgen de la interacción de varios genes, además de la posible interacción con el medio ambiente. 
Nuestro objetivo final es detectar donde se encuentran estos genes, que producen cambios en rasgos cuantitativos (los llamados QTLs), pero realmente a priori no sabemos cuáles son. Por tanto, el procedimiento habitual es marcar tramos de la secuencia de ADN (lo que se conoce como marcador genético) y estudiar si entre dos de ellos existen diferencias cuando el rasgo que queremos comprender es diferente. 

Es intuitivo observar que nuestro resultados no pueden quedarse aquí, puesto que los marcadores genéticos pueden contener una gran cantidad de genes distintos. Surge la necesidad de la primera herramienta estadística que sería una regresión desde el marcador hasta el gen que queremos buscar. Nuestros problemas no acaban ahí, y es que durante la división celular sabemos que se se produce una recombinación genética con lo que la información que nos proporcionan los marcadores puede verse alterada. 
En resumen, para llevar a cabo este estudio analizaremos diferencias entre marcadores genéticos entre dos poblaciones (retrocruzadas\footnote{El retrocruzamiento es un proceso experimental que se lleva a cabo con el fin de obetener individuos homocigóticos (ambos cromosomas idénticos en ambas posiciones)}) que presente dimorfismo en el rasgo que nos interesa, buscando hacer inferencia de las diferencias entre QTLs usando los marcadores.

\subsection{Ejemplos de aplicaciones de test de hipótesis}
La manera más simple de identificar si existe o no un QTL en dos poblaciones, es considerar cada marcador al que tenemos acceso individualmente, dividir los individuos según su genotipo (homocigóticos y heterocigóticos) y, para cada marcador genético, hacer un test de la $t$ de Student de comparación de dos poblaciones (diferenciadas en nuestro caso por el rasgo escogido), puesto que no es descabellado pensar que al tratar con un rasgo cuantitativo en dos poblaciones, éste venga determinado por una distribución normal.

Planteando el problema en un lenguaje más matemático, estamos ante dos expresiones diferentes de un rasgo. En la población 1, el rasgo sigue una distribución $N(\mu_1,\sigma)$ y en la población 2, el rasgo sigue una distribución $N(\mu_2,\sigma)$, siendo la $H_0:$ No existen diferencias significativas entre ambas medias poblacionales (o, más específicamente hablando, no hay una diferencia significativa en los genes del marcador seleccionado\footnote{En realidad la hipótesis nula que vamos buscando es la no existencia de diferencias entre todos los marcadores, pero en esta breve exposición de aplicaciones, no vamos a profundizar a tanto nivel}).
Como podemos ver, es un test de comparación de medias.

Por otra parte, también es habitual realizar test de contraste de hipótesis conocida una región determinada de nuestro marcador. En ese caso se utiliza un estadístico particular LOD (logaritmos de las odd ratio a favor de una relación QTL). Este estadístico como se expone en,\cite{uned2} tiene una distribución aproximada $\chi^2$
con lo que podremos utilizar los test para esta distribución.
Sin embargo, como apuntábamos, si queremos centrarnos en todo el genoma, debemos modificar estos test y con ello los estadísticos en los que se basan. 

Exponemos así que lo dicho en el trabajo es solo una pincelada de las aplicaciones de los test de hipótesis y también de la teoría estadística en la que yacen. Conforme surgen nuevos problemas en biología y en especial en bioinformática con su actual auge, la estadística también debe evolucionar.





























\bibliographystyle{apalike}
\bibliography{bibliography/bibliografia}

\end{document}
